{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import re\n",
    "import requests\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Data - Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid_data():\n",
    "    client = Socrata(\"data.cdc.gov\", None)\n",
    "    results = client.get(\"9mfq-cb36\", limit=20000)\n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    df[\"submission_date\"] = pd.to_datetime(df[\"submission_date\"], format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Unemployment Claims - FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icsa_data_fred(key):\n",
    "    url = f'https://api.stlouisfed.org/fred/series/observations?series_id=ICSA&api_key={key}&file_type=json'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    weeks = []\n",
    "    claims = []\n",
    "    \n",
    "    for i in data['observations']:\n",
    "        weeks.append(i['date'])\n",
    "        claims.append(i['value'])\n",
    "\n",
    "    dict = {\"Date\": weeks,\n",
    "            \"Claims\": claims}    \n",
    "        \n",
    "    df = pd.DataFrame(dict)    \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data - Pandas DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(start, end, ticker):\n",
    "        \n",
    "    df = web.DataReader(name=ticker, data_source='yahoo', start=start, end=end)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df['Ticker'] = str(ticker).replace(\"^\",\"\")\n",
    "    df = df[df.columns[[7,0,1,2,3,4,5,6]]]\n",
    "    #stocks.append(df)\n",
    "        \n",
    "    #dff = pd.concat(stocks)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presidential Election 2020 Results - USA Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_presidential_results():\n",
    "\n",
    "    url = 'https://www.usatoday.com/elections/results/2020-11-03/presidential/'\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    \n",
    "    all_dfs = []\n",
    "\n",
    "    for t in soup.find_all(\"div\", attrs={\"class\":\"result-table-block\"}):\n",
    "\n",
    "        # State\n",
    "        state_soup = t.find(attrs={\"class\":\"result-table-header\"})\n",
    "        state = state_soup.text\n",
    "        #print(state)\n",
    "\n",
    "        # Candidates\n",
    "        candidates_soup = t.find_all(\"span\", attrs={\"class\":\"result-table-col-candidate-first-name\"})\n",
    "        candidates = [(f'{i.text} {i.next_sibling}').replace(\"\\n\", \"\").replace(\" *\", \"\") for i in candidates_soup]\n",
    "        party = [i[i.find(\"(\")+1:i.find(\")\")]for i in candidates]\n",
    "        candidates = [i[:-4].rstrip() for i in candidates]    \n",
    "\n",
    "        # Votes\n",
    "        votes_soup = t.find_all(\"td\", attrs={\"class\":\"result-table-col-votes\"})\n",
    "        votes = [i.contents[0].replace(\",\", \"\") for i in votes_soup]\n",
    "\n",
    "        # Percentage of Votes\n",
    "        vote_percentage_soup = t.find_all(\"td\", attrs={\"class\":\"result-table-col-percent\"})\n",
    "        vote_percentage = [str(round(float(i.contents[0].replace(\"%\", \"\"))/100,2)) for i in vote_percentage_soup]\n",
    "\n",
    "        # Electoral Votes\n",
    "        electoral_votes_soup = t.find_all(\"th\", attrs={\"class\":\"result-table-col-ev\"})\n",
    "        electoral_votes = [i.contents[0] for i in electoral_votes_soup]\n",
    "        electoral_votes = electoral_votes[1:]\n",
    "        electoral_votes = [i.replace(\"-\", \"0\") for i in electoral_votes]\n",
    "\n",
    "        dict = {'Candidates': candidates,\n",
    "                   'Party': party,\n",
    "                   'Votes': votes,\n",
    "                   'Vote Percentage': vote_percentage,\n",
    "                   'Electoral Votes': electoral_votes}\n",
    "\n",
    "        df = pd.DataFrame(dict)\n",
    "        df['State'] = state\n",
    "        df = df[df.columns[[5,0,1,2,3,4]]]\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Billboard Year-End Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_end_song_charts():\n",
    "    \n",
    "    url = 'https://www.billboard.com/charts/year-end'\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "    charts = []\n",
    "\n",
    "    for i in links:\n",
    "        link = i['href']\n",
    "        if re.search(\"/charts/year-end/2020\", link):\n",
    "            link = link.split('charts/year-end/2020/')[1]\n",
    "            if link.endswith(\"-songs\"):\n",
    "                charts.append(link)\n",
    "                \n",
    "    return charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_year_end_chart(year, chart):\n",
    "    \n",
    "    url = f'https://www.billboard.com/charts/year-end/{year}/{chart}'\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    song_blocks = soup.find_all(\"article\", attrs={\"class\":\"ye-chart-item\"})\n",
    "    \n",
    "    songs = []\n",
    "    \n",
    "    for i in song_blocks:\n",
    "        \n",
    "        temp_dict = {}\n",
    "        \n",
    "        # Song Ranking\n",
    "        rank = i.find(\"div\", attrs={\"class\":\"ye-chart-item__rank\"}).text.replace(\"\\n\", \"\")\n",
    "        temp_dict[\"rank\"] = rank\n",
    "        \n",
    "        # Song Title\n",
    "        title = i.find(\"div\", attrs={\"class\":\"ye-chart-item__title\"}).text.replace(\"\\n\", \"\")\n",
    "        temp_dict[\"title\"] = title\n",
    "        \n",
    "\n",
    "        # Song Artist\n",
    "        artist = i.find(\"div\", attrs={\"class\":\"ye-chart-item__artist\"}).text.replace(\"\\n\", \"\")\n",
    "        temp_dict[\"artists\"] = artist\n",
    "        \n",
    "        # Chart\n",
    "        temp_dict[\"chart\"] = chart\n",
    "        \n",
    "        songs.append(temp_dict)\n",
    "        \n",
    "    return songs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
